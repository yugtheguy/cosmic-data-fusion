"""
FITS Adapter - Stage 5: API Integration Testing
===============================================

Tests the complete end-to-end API integration for FITS file ingestion.
- Tests HTTP request/response with FastAPI
- Tests file upload mechanism
- Tests error handling and validation
- Tests dataset isolation
"""

import sys
import os
import json
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pytest
from app.models import UnifiedStarCatalog

# Test data path
TEST_DATA_DIR = Path(__file__).parent.parent / "app" / "data"


class TestFITSAPIIntegration:
    """Test FITS API endpoints end-to-end"""

    def test_health_check(self, client):
        """Verify API is healthy"""
        print("\nSTAGE 5 TEST: Health Check")
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"
        print(f"[OK] API health check: {data}")

    def test_fits_ingest_hipparcos(self, client, db_session):
        """Test FITS ingestion via API - Hipparcos catalog"""
        print("\nSTAGE 5 TEST: Hipparcos FITS Ingestion via API")
        
        fits_file = TEST_DATA_DIR / "hipparcos_sample.fits"
        assert fits_file.exists(), f"Test file not found: {fits_file}"
        
        with open(fits_file, "rb") as f:
            files = {"file": ("hipparcos_sample.fits", f, "application/octet-stream")}
            data = {
                "dataset_id": "api_hipparcos_test",
                "skip_invalid": True
            }
            response = client.post("/ingest/fits", files=files, data=data)
        
        print(f"  Response status: {response.status_code}")
        assert response.status_code == 200
        
        result = response.json()
        print(f"  Response: {json.dumps(result, indent=2)}")
        
        assert result["success"] == True
        assert result["ingested_count"] > 0
        assert result["failed_count"] >= 0
        # Note: dataset_id is auto-generated by adapter
        assert result["dataset_id"] is not None
        assert "catalog_info" in result
        
        # Verify records in database
        records = db_session.query(UnifiedStarCatalog).filter_by(
            dataset_id="api_hipparcos_test"
        ).all()
        
        print(f"  [OK] {len(records)} records verified in database")
        assert len(records) == result["ingested_count"]
        
        # Verify star data integrity
        sample = records[0]
        print(f"  Sample record: object_id={sample.object_id}, RA={sample.ra_deg:.4f}, "
              f"Dec={sample.dec_deg:.4f}, Mag={sample.brightness_mag:.2f}")
        assert sample.ra_deg is not None
        assert sample.dec_deg is not None
        assert sample.brightness_mag is not None

    def test_fits_ingest_2mass(self, client, db_session):
        """Test FITS ingestion via API - 2MASS catalog"""
        print("\nSTAGE 5 TEST: 2MASS FITS Ingestion via API")
        
        fits_file = TEST_DATA_DIR / "2mass_sample.fits"
        assert fits_file.exists(), f"Test file not found: {fits_file}"
        
        with open(fits_file, "rb") as f:
            files = {"file": ("2mass_sample.fits", f, "application/octet-stream")}
            data = {
                "dataset_id": "api_2mass_test",
                "skip_invalid": True
            }
            response = client.post("/ingest/fits", files=files, data=data)
        
        print(f"  Response status: {response.status_code}")
        assert response.status_code == 200
        
        result = response.json()
        print(f"  Response: {json.dumps(result, indent=2)}")
        
        assert result["success"] == True
        assert result["ingested_count"] > 0
        dataset_id_2mass = result["dataset_id"]
        
        # Verify records in database
        records = db_session.query(UnifiedStarCatalog).filter_by(
            dataset_id=dataset_id_2mass
        ).all()
        
        print(f"  [OK] {len(records)} records verified in database")
        assert len(records) == result["ingested_count"]

    def test_fits_ingest_multi_extension(self, client):
        """Test FITS ingestion with extension selection"""
        print("\nSTAGE 5 TEST: Multi-Extension FITS Ingestion")
        
        fits_file = TEST_DATA_DIR / "fits_multi_extension.fits"
        assert fits_file.exists(), f"Test file not found: {fits_file}"
        
        # Test default (first extension)
        with open(fits_file, "rb") as f:
            files = {"file": ("fits_multi_extension.fits", f, "application/octet-stream")}
            data = {
                "dataset_id": "api_multi_ext_default",
                "skip_invalid": True
            }
            response = client.post("/ingest/fits", files=files, data=data)
        
        print(f"  Default extension response status: {response.status_code}")
        assert response.status_code == 200
        result = response.json()
        assert result["success"] == True
        print(f"  [OK] Default extension ingested {result['ingested_count']} records")
        
        # Test specific extension
        with open(fits_file, "rb") as f:
            files = {"file": ("fits_multi_extension.fits", f, "application/octet-stream")}
            data = {
                "dataset_id": "api_multi_ext_extension2",
                "extension": 2,
                "skip_invalid": True
            }
            response = client.post("/ingest/fits", files=files, data=data)
        
        print(f"  Extension 2 response status: {response.status_code}")
        assert response.status_code == 200
        result = response.json()
        assert result["success"] == True
        print(f"  [OK] Extension 2 ingested {result['ingested_count']} records")

    def test_fits_ingest_with_error_handling(self, client):
        """Test API error handling for invalid FITS"""
        print("\nSTAGE 5 TEST: Error Handling - Invalid FITS File")
        
        # Create invalid FITS data
        invalid_fits = b"This is not a valid FITS file"
        
        files = {"file": ("invalid.fits", invalid_fits, "application/octet-stream")}
        data = {"dataset_id": "api_error_test", "skip_invalid": True}
        response = client.post("/ingest/fits", files=files, data=data)
        
        print(f"  Response status: {response.status_code}")
        # Should return 400 or 422 for invalid file
        assert response.status_code in [400, 422, 500]
        
        error_data = response.json()
        print(f"  Error response: {json.dumps(error_data, indent=2)}")
        assert "detail" in error_data or "error" in error_data or "message" in error_data

    def test_fits_dataset_isolation(self, db_session):
        """Test that different datasets are properly isolated"""
        print("\nSTAGE 5 TEST: Dataset Isolation")
        
        # Count records by unique dataset IDs (auto-generated)
        all_records = db_session.query(UnifiedStarCatalog).all()
        dataset_ids = set(r.dataset_id for r in all_records if r.dataset_id)
        
        total_count = len(all_records)
        
        print(f"  Total records: {total_count}")
        print(f"  Unique datasets: {len(dataset_ids)}")
        print(f"  Dataset IDs: {dataset_ids}")
        
        assert total_count > 0
        assert len(dataset_ids) > 0
        print(f"  [OK] Datasets properly isolated")

    def test_query_across_datasets(self, db_session):
        """Test querying across different FITS datasets"""
        print("\nSTAGE 5 TEST: Cross-Dataset Query")
        
        # Query all bright stars across all FITS datasets
        bright_stars = db_session.query(UnifiedStarCatalog).filter(
            UnifiedStarCatalog.brightness_mag <= 8.0
        ).all()
        
        print(f"  Bright stars (mag <= 8.0) across all datasets: {len(bright_stars)}")
        
        if bright_stars:
            sample = bright_stars[0]
            print(f"  Sample: {sample.object_id}, dataset={sample.dataset_id}, "
                  f"RA={sample.ra_deg:.2f}, Dec={sample.dec_deg:.2f}, "
                  f"Mag={sample.brightness_mag:.2f}")
        
        assert len(bright_stars) >= 0

    def test_spatial_query_api_data(self, db_session):
        """Test spatial queries on API-ingested data"""
        print("\nSTAGE 5 TEST: Spatial Queries on API Data")
        
        # Find any test records from API ingestion
        test_records = db_session.query(UnifiedStarCatalog).limit(5).all()
        
        if test_records:
            test_record = test_records[0]
            print(f"  Testing cone search around: RA={test_record.ra_deg:.2f}, "
                  f"Dec={test_record.dec_deg:.2f}")
            
            # Spatial query (simple distance in degrees)
            radius = 10.0
            nearby = db_session.query(UnifiedStarCatalog).filter(
                (UnifiedStarCatalog.ra_deg - test_record.ra_deg)**2 +
                (UnifiedStarCatalog.dec_deg - test_record.dec_deg)**2 <= radius**2
            ).all()
            
            print(f"  Stars within {radius} degree radius: {len(nearby)}")
            assert len(nearby) >= 1

    def test_api_response_format(self, client):
        """Verify API response format matches specification"""
        print("\nSTAGE 5 TEST: API Response Format")
        
        fits_file = TEST_DATA_DIR / "hipparcos_sample.fits"
        
        with open(fits_file, "rb") as f:
            files = {"file": ("hipparcos_sample.fits", f, "application/octet-stream")}
            data = {"skip_invalid": True}
            response = client.post("/ingest/fits", files=files, data=data)
        
        assert response.status_code == 200
        result = response.json()
        
        # Verify response structure
        required_fields = [
            "success", "ingested_count", "failed_count", "dataset_id",
            "file_name", "catalog_info", "message"
        ]
        
        for field in required_fields:
            assert field in result, f"Missing required field: {field}"
            print(f"  [OK] Field '{field}': {result[field]}")
        
        # Verify types
        assert isinstance(result["success"], bool)
        assert isinstance(result["ingested_count"], int)
        assert isinstance(result["failed_count"], int)
        assert isinstance(result["dataset_id"], str)

    def test_performance_large_dataset(self, client):
        """Test performance with full FITS file"""
        print("\nSTAGE 5 TEST: Performance - Large FITS File")
        
        fits_file = TEST_DATA_DIR / "hipparcos_sample.fits"
        
        import time
        start_time = time.time()
        
        with open(fits_file, "rb") as f:
            files = {"file": ("hipparcos_sample.fits", f, "application/octet-stream")}
            data = {"skip_invalid": True}
            response = client.post("/ingest/fits", files=files, data=data)
        
        elapsed = time.time() - start_time
        
        assert response.status_code == 200
        result = response.json()
        
        records_per_sec = result["ingested_count"] / elapsed if elapsed > 0 else 0
        print(f"  Ingestion time: {elapsed:.2f}s")
        print(f"  Records ingested: {result['ingested_count']}")
        print(f"  Throughput: {records_per_sec:.1f} records/sec")
        
        # Reasonable performance threshold
        if result["ingested_count"] > 0:
            assert records_per_sec > 50, f"Slow ingestion: {records_per_sec:.1f} records/sec"


class TestAPIEndpoints:
    """Test other API endpoints with FITS data"""

    def test_search_endpoint_with_fits_data(self, client, db_session):
        """Test search endpoint with FITS-ingested data"""
        print("\nSTAGE 5 TEST: Search Endpoint with FITS Data")
        
        total_records = db_session.query(UnifiedStarCatalog).count()
        
        if total_records == 0:
            print("  [SKIP] Skipping - no FITS data in database")
            return
        
        # Search for bright stars
        response = client.get("/search", params={
            "magnitude_max": 8.0
        })
        
        print(f"  Response status: {response.status_code}")
        assert response.status_code == 200
        
        result = response.json()
        print(f"  Found {len(result.get('results', []))} bright stars")

    def test_harmonize_endpoint_with_fits(self, client, db_session):
        """Test harmonize endpoint with FITS data"""
        print("\nSTAGE 5 TEST: Harmonize Endpoint with FITS Data")
        
        first_dataset = db_session.query(UnifiedStarCatalog).first()
        
        if not first_dataset:
            print("  [SKIP] Skipping - no FITS data in database")
            return
        
        response = client.post("/harmonize", json={
            "dataset_id": first_dataset.dataset_id,
            "target_schema": "extended"
        })
        
        print(f"  Response status: {response.status_code}")
        if response.status_code == 200:
            result = response.json()
            print(f"  [OK] Harmonization completed: {result}")


def run_all_tests():
    """Run all API integration tests"""
    print("\n" + "="*80)
    print("FITS ADAPTER - STAGE 5: API INTEGRATION TESTING")
    print("="*80)
    
    pytest.main([__file__, "-v", "-s"])


if __name__ == "__main__":
    run_all_tests()
