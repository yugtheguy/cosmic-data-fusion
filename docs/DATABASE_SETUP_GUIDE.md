## PostgreSQL / PostGIS (Windows)

This project can run against a PostgreSQL database with PostGIS enabled. You can either run PostgreSQL/PostGIS in Docker or install PostgreSQL natively on Windows.

### Enabling PostGIS via Alembic

An Alembic migration that enables PostGIS is included:

- `alembic/versions/0001_enable_postgis.py` â€” runs `CREATE EXTENSION IF NOT EXISTS postgis;`

To apply migrations once a PostgreSQL instance is available, set your `DATABASE_URL` environment variable and run:

```powershell
setx DATABASE_URL "postgresql+psycopg2://postgres:password@localhost:5432/cosmic"
python -m alembic upgrade head
```

Replace the connection string values above for your setup (`user`, `password`, `host`, `port`, `database`).

### Windows native install (PostgreSQL + PostGIS)

If you have a PostgreSQL installer on your machine (e.g. the one shown in the project screenshot), run the installer and then install PostGIS via StackBuilder or by running the `CREATE EXTENSION postgis;` SQL command in `psql` or a DB client connected as a superuser.

PowerShell command to run the included PostgreSQL installer (run as Administrator):

```powershell
# Run installer (replace path if different)
Start-Process -FilePath "C:\Program Files\PostgreSQL\postgresql_18\installer.exe" -Verb RunAs
```

After installation, create a database and enable PostGIS:

```sql
-- connect as superuser
CREATE DATABASE cosmic;
\c cosmic
CREATE EXTENSION IF NOT EXISTS postgis;
```

### Docker (recommended if Docker is available)

If Docker Desktop can run on your machine, start the `postgres` service from `docker-compose.yml` and then apply migrations:

```powershell
# from repo root
docker-compose up -d postgres
# set DATABASE_URL to point to the container and then
python -m alembic upgrade head
```

If Docker Desktop is not currently running, you can either enable WSL2/Hyper-V or use the native installer.
# ðŸ—„ï¸ Database Setup Guide: PostgreSQL, PostGIS & Redis

**Current Status:** Using SQLite (local development)  
**Next Level:** PostgreSQL + PostGIS + Redis (production-ready)

---

## ðŸ“‹ DATABASE UPGRADE STRATEGY

### What We Have Now (SQLite)
```
âœ“ Simple, file-based
âœ“ Good for development
âœ“ Limited spatial features
âœ— Not scalable for 100K+ records
âœ— No caching layer
```

### What We Should Add (Production Stack)
```
PostgreSQL + PostGIS:
  âœ“ Relational database (scalable)
  âœ“ ACID transactions
  âœ“ Spatial queries (cone search, bounding box)
  âœ“ Handles millions of records
  âœ“ Vector/raster support
  
Redis:
  âœ“ In-memory cache layer
  âœ“ Fast query results
  âœ“ Session management
  âœ“ Real-time data aggregation
```

---

## ðŸ”§ SETUP PLAN (4 Steps)

### Step 1: Install PostgreSQL + PostGIS

**Windows:**
```bash
# Option A: PostgreSQL installer with PostGIS
# Download: https://www.postgresql.org/download/windows/
# During installation, select "PostGIS" extension

# Option B: Using Docker (recommended)
docker run --name cosmic_postgres \
  -e POSTGRES_DB=cosmic_data \
  -e POSTGRES_USER=cosmic_user \
  -e POSTGRES_PASSWORD=secure_password \
  -p 5432:5432 \
  postgis/postgis:15-3.3 \
  -d
```

**Connection String:**
```
postgresql://cosmic_user:secure_password@localhost:5432/cosmic_data
```

---

### Step 2: Install Redis

**Windows:**
```bash
# Option A: Using Docker (easiest)
docker run --name cosmic_redis \
  -p 6379:6379 \
  -d \
  redis:7-alpine

# Option B: WSL2 (Windows Subsystem for Linux)
wsl apt-get install redis-server
redis-server
```

**Connection String:**
```
redis://localhost:6379/0
```

---

### Step 3: Update SQLAlchemy Configuration

**File to modify:** `app/database.py`

```python
# Current (SQLite)
SQLALCHEMY_DATABASE_URL = "sqlite:///./cosmic_data.db"

# New (PostgreSQL)
SQLALCHEMY_DATABASE_URL = "postgresql://cosmic_user:secure_password@localhost:5432/cosmic_data"

# Or from environment variables (recommended)
import os
SQLALCHEMY_DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://cosmic_user:secure_password@localhost:5432/cosmic_data"
)
```

---

### Step 4: Add PostGIS Support

**Install dependency:**
```bash
pip install geoalchemy2
```

**Update models.py to use PostGIS geometry:**
```python
from geoalchemy2 import Geometry

# Instead of separate ra_deg, dec_deg
# Add spatial column:
location = Column(Geometry('POINT', srid=4035))  # ICRS coordinates

# Or keep both for flexibility:
# ra_deg + dec_deg (numeric)
# location (geometry point)
```

---

## ðŸŽ¯ RECOMMENDED SETUP (Production)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FastAPI Application                           â”‚
â”‚             (Gaia + SDSS + FITS + CSV Adapters)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                 â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚ PostGIS      â”‚   â”‚   Redis     â”‚
â”‚ (Primary DB) â”‚ (Spatial)    â”‚   â”‚ (Cache)     â”‚
â”‚              â”‚              â”‚   â”‚             â”‚
â”‚ âœ“ 10M+ stars â”‚ âœ“ Cone searchâ”‚   â”‚ âœ“ Query cache
â”‚ âœ“ ACID      â”‚ âœ“ Bounding boxâ”‚  â”‚ âœ“ Sessions
â”‚ âœ“ Indexes   â”‚ âœ“ Nearest N  â”‚   â”‚ âœ“ Analytics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¾ WHAT TO MIGRATE

| Feature | SQLite | PostgreSQL | PostGIS | Redis |
|---------|--------|------------|---------|-------|
| **Data Storage** | âœ“ | âœ“ | âœ“ | âœ— |
| **ACID Transactions** | âœ“ | âœ“ | âœ“ | âœ— |
| **Spatial Queries** | âœ— | ~ | âœ“âœ“âœ“ | âœ— |
| **Cone Search** | âœ— | âœ— | âœ“ | âœ— |
| **Bounding Box** | âœ“ | âœ“ | âœ“âœ“ | âœ— |
| **KNN (K-Nearest)** | âœ— | âœ— | âœ“ | âœ— |
| **Caching** | âœ— | âœ— | âœ— | âœ“âœ“âœ“ |
| **Real-time Aggregation** | âœ— | âœ— | âœ— | âœ“âœ“ |
| **Scale (Records)** | 100K | 100M | 100M | N/A |

---

## ðŸ”„ MIGRATION PATH (Step-by-Step)

### Phase 1: PostgreSQL (Keep SQLite temporarily)
```
1. Install PostgreSQL
2. Create database: cosmic_data
3. Update DATABASE_URL in code
4. Run migrations (create tables)
5. Migrate data: SQLite â†’ PostgreSQL
6. Keep SQLite as backup
7. Switch application to PostgreSQL
```

### Phase 2: Add PostGIS
```
1. Install PostGIS extension
2. Add geometry columns to tables
3. Add spatial indexes
4. Update queries to use ST_Distance, ST_DWithin, etc.
5. Test cone search queries
```

### Phase 3: Add Redis Caching
```
1. Install Redis
2. Add redis-py package
3. Cache frequent queries
4. Cache visualization data (/visualize/*)
5. Cache dataset statistics
```

---

## ðŸ“ EXAMPLE: CONE SEARCH WITH PostGIS

**Current SQLite (approximate):**
```python
# Distance calculation at application level
results = db.query(UnifiedStarCatalog).filter(
    (UnifiedStarCatalog.ra_deg >= ra - radius/cos(dec)) &
    (UnifiedStarCatalog.ra_deg <= ra + radius/cos(dec)) &
    (UnifiedStarCatalog.dec_deg >= dec - radius) &
    (UnifiedStarCatalog.dec_deg <= dec + radius)
).all()
```

**With PostGIS (optimized):**
```python
from geoalchemy2.functions import ST_DWithin
from geoalchemy2 import Geometry

# Direct spatial query (much faster!)
results = db.query(UnifiedStarCatalog).filter(
    ST_DWithin(
        UnifiedStarCatalog.location,
        f'POINT({ra} {dec})',
        radius / 3600.0  # Convert arcsec to degrees
    )
).all()
```

---

## ðŸš€ IMPLEMENTATION PRIORITY

**NOW (Keep SQLite for dev):**
- âœ“ Gaia adapter working with SQLite
- âœ“ SDSS adapter working with SQLite
- âœ“ FITS adapter working with SQLite

**NEXT SPRINT (Add PostgreSQL):**
- 1. Set up PostgreSQL + PostGIS
- 2. Migrate UnifiedStarCatalog schema
- 3. Update connection string
- 4. Test all adapters with PostgreSQL
- 5. Optimize spatial indexes

**FUTURE SPRINTS (Add Redis):**
- 1. Set up Redis
- 2. Cache visualization endpoints
- 3. Cache dataset statistics
- 4. Performance testing

---
